---
layout: page
title: Publications
#subtitle: "Respect, Respond, Realize."
---

<p class="about-users">
<center><span class="fa fa-users about-icon"></span> <strong> Conference Proceedings </strong>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<span class="fa fa-file about-icon"></span> <strong> Poster </strong></center>

<h3><span class="fa fa-users about-icon"></span> &nbsp;HARNet: Towards On-Device Incremental Learning using Deep Ensembles on Constrained Devices</h3>
<h4><i>2nd International Workshop on Embedded and Mobile Deep Learning (Co-located with ACM MobiSys 2018)</i></h4>
✔ Developed a Human Activity Recognition (HAR) system robust to mobile-sensing heterogeneities on Embedded platforms using Deep Learning.<br>
✔ Proposed a novel ensembled Deep learning architecture using Convolutional Neural Nets (CNN) and Recurrent Neural Nets (RNN), which facilitates on-device Incremental learning.<br>
✔ Wavelet Transform and Downsampling using Decimation was performed on accelerometer data alone to attain sensor minimization, thereby enabling feasibility on embedded and mobile devices.<br><br>

<h3><span class="fa fa-users about-icon"></span> &nbsp;<a href="http://saiconference.com/FICC2018/Agenda">A Generic Multi-modal Dynamic Gesture Recognition System using Machine Learning</a></h3>
<h4><i><a href="http://saiconference.com/FICC" target="_blank">IEEE Future of Information and Communications Conference (FICC 2018), Singapore</a></i></h4>
<h5><center><a href="/FICC_2018.pdf">[View Paper]</a></center></h5>
✔ Human Computer Interaction facilitates intelligent communication between humans and computers, in which gesture recognition plays a prominent role. This paper presents a machine learning system to identify dynamic gestures using two accelerometer-based datasets, characterized by a generic set of features across time & frequency domains.<br>
✔ The engine was analyzed from an end-user perspective and was modelled to operate in three modes. The modes of operation determine the subsets of data to be used for training and testing the system. From an initial set of seven classifiers, three were chosen to evaluate each dataset across all modes rendering the system towards mode-neutrality and dataset-independence.<br>
✔ The proposed system is able to classify gestures performed at varying speeds with minimum preprocessing, making it computationally efficient. This engine runs on a low-cost embedded platform like Raspberry Pi Zero (USD 5), making it economically viable.<br><br>

<h3><span class="fa fa-users about-icon"></span> &nbsp;<a href="https://link.springer.com/chapter/10.1007/978-981-10-5780-9_13" target="_blank">Electroencephalography Based Analysis of Emotions Among Indian Film Viewers</a></h3>
<h4><i>International Conference on Advanced Informatics for Computing Research <br>(ICAICR 2017), Springer</i></h4>
<h5><center><a href="/ICAICR_2017.pdf">[View Paper]</a></center></h5>
✔ Neurocinematics is an emerging field of research that measures the cognitive responses of a film viewer. In this paper, the real-time brainwave frequencies of viewers watching two different genres of Indian films - horror and comedy, were captured using a Neurosky Mindwave Mobile EEG device.<br>
✔ The data was analyzed for each time interval and the resultant frequency observed was compared with various frequency ranges of brainwaves, thus attributing to the different emotions of the viewers watching the movie at every point of time.<br>
✔ The results have matched with the intended emotions, in turn the genre of the movie, which was determined based on the released movies' IMDb reviews.<br><br>

<h3><span class="fa fa-users about-icon"></span> &nbsp;<a href="http://www.sciencedirect.com/science/article/pii/S1877050916305002" target="_blank">Analysis of Routing Protocol for Low-power & Lossy Networks in IoT Real Time Applications</a></h3>
<h4><i>Fourth International Conference on Recent Trends in Computer Science & Engineering (ICRTCSE 2016), Elsevier</i></h4>
<h5><center><a href="/ICRTCSE_2016.pdf">[View Paper]</a></center></h5>
✔ Implemented a comparison of performance metrics in RPL between two real-time scenarios, such that they well-adapted to differentiate, thereby choosing a proper mote for the respective environment.<br>
✔ Used Contiki OS as a testbed for simulation via Cooja Simulator to process metrics of the sensory motes in a virtual WSN so that a trade-off was made between Zolertia Z1 mote and WiSMote.<br>
✔ The environments of Smart Building and Agriculture were pre-considered and patterns of Latency, Received Packets per Node and Routing Metrics were observed with an average of 10 and 20 senders, for 1 or 2 sinks.<br><br>

<h3><span class="fa fa-file about-icon"></span> &nbsp;<a href="/CBC_Poster.pdf">Neurocinematics: The Intelligent Review System</a></h3>
<h4><i><a href="https://pdfs.semanticscholar.org/582b/3762fc4e6ba6359d96d4f7bfc2c35e75fd66.pdf" target="_blank">3rd International Conference on Cognition, Brain and Computation (CBC 2015), <br>IIT Gandhinagar</a></i></h4>
✔ While watching a film, the viewers undergo an experience that evolves over time, which grabs their attention and triggers a sequence of processes, which is perceptual, cognitive, and emotional. Each producer invests millions of dollars in a film, with the great uncertainty of getting the invested money back (leave alone the profit).<br>
✔ This article proposes to use the advancements in the EEG to address the above problem, at the same time retaining the merits of the existing methods such as FMRI. The idea is about taking a pre-release live review for a film using specially coded brainwaves from headsets (EEG) placed onto the viewers heads.<br>
✔ We propose that EEG studies of brain and its mapping will act as a fail-proof coating for each film and help the producers to bring out what they intended. All the results obtained from this experiment are solely indented to bridge the gap between mind of a viewer and the film he is viewing.


